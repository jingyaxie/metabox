# MetaBox RAGä¼˜åŒ–æŠ€æœ¯å®ç°æ–¹æ¡ˆ

## ğŸ“‹ æŠ€æœ¯èƒŒæ™¯

åŸºäºå¯¹Difyå’ŒLangChainæŠ€æœ¯ç‚¹çš„æ·±å…¥åˆ†æï¼ŒMetaBoxå°†å®ç°ä¸€å¥—å®Œæ•´çš„RAGä¼˜åŒ–æŠ€æœ¯æ ˆï¼Œæå‡æ£€ç´¢ç²¾åº¦å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯å®ç°

### 1. æ™ºèƒ½æ–‡æ¡£åˆ†å‰²ä¸å‘é‡åŒ–é…ç½®ç³»ç»Ÿ

#### 1.1 æ–‡æ¡£ç±»å‹æ™ºèƒ½æ£€æµ‹
```python
class DocumentTypeDetector:
    """æ–‡æ¡£ç±»å‹æ™ºèƒ½æ£€æµ‹å™¨"""
    def __init__(self):
        self.type_patterns = {
            "markdown": [r"^#\s+", r"^##\s+", r"^###\s+"],
            "code": [r"```[\w]*\n", r"import\s+", r"def\s+", r"class\s+"],
            "technical": [r"API", r"æ¥å£", r"å‚æ•°", r"é…ç½®"],
            "academic": [r"æ‘˜è¦", r"Abstract", r"å‚è€ƒæ–‡çŒ®", r"References"],
            "news": [r"æœ¬æŠ¥è®¯", r"è®°è€…", r"æ—¶é—´", r"åœ°ç‚¹"],
            "manual": [r"ä½¿ç”¨è¯´æ˜", r"æ“ä½œæ­¥éª¤", r"æ³¨æ„äº‹é¡¹", r"FAQ"]
        }
    
    def detect_document_type(self, text: str) -> Dict[str, float]:
        """æ£€æµ‹æ–‡æ¡£ç±»å‹åŠç½®ä¿¡åº¦"""
        scores = {}
        for doc_type, patterns in self.type_patterns.items():
            score = sum(len(re.findall(pattern, text)) for pattern in patterns)
            scores[doc_type] = score / len(text) * 1000  # å½’ä¸€åŒ–
        return scores
    
    def get_primary_type(self, text: str) -> str:
        """è·å–ä¸»è¦æ–‡æ¡£ç±»å‹"""
        scores = self.detect_document_type(text)
        return max(scores.items(), key=lambda x: x[1])[0]
```

#### 1.2 æ™ºèƒ½å‚æ•°æ¨èå¼•æ“
```python
class SmartParameterRecommender:
    """æ™ºèƒ½å‚æ•°æ¨èå¼•æ“"""
    def __init__(self):
        self.recommendations = {
            "markdown": {
                "splitter": "markdown_header",
                "chunk_size": 512,
                "chunk_overlap": 64,
                "embedding_model": "bge-m3",
                "use_parent_child": True
            },
            "code": {
                "splitter": "recursive",
                "chunk_size": 256,
                "chunk_overlap": 32,
                "embedding_model": "code-embedding-model",
                "use_parent_child": False
            },
            "technical": {
                "splitter": "recursive",
                "chunk_size": 384,
                "chunk_overlap": 48,
                "embedding_model": "bge-m3",
                "use_parent_child": True
            },
            "academic": {
                "splitter": "semantic",
                "chunk_size": 768,
                "chunk_overlap": 96,
                "embedding_model": "bge-m3",
                "use_parent_child": True
            },
            "news": {
                "splitter": "recursive",
                "chunk_size": 256,
                "chunk_overlap": 32,
                "embedding_model": "text-embedding-ada-002",
                "use_parent_child": False
            },
            "manual": {
                "splitter": "markdown_header",
                "chunk_size": 384,
                "chunk_overlap": 48,
                "embedding_model": "bge-m3",
                "use_parent_child": True
            }
        }
    
    def get_recommendation(self, doc_type: str, text_length: int = 0) -> Dict[str, Any]:
        """è·å–å‚æ•°æ¨è"""
        base_config = self.recommendations.get(doc_type, self.recommendations["technical"])
        
        # æ ¹æ®æ–‡æœ¬é•¿åº¦è°ƒæ•´å‚æ•°
        if text_length > 10000:
            base_config["chunk_size"] = min(base_config["chunk_size"] * 1.5, 1024)
            base_config["chunk_overlap"] = min(base_config["chunk_overlap"] * 1.2, 128)
        elif text_length < 1000:
            base_config["chunk_size"] = max(base_config["chunk_size"] * 0.7, 128)
            base_config["chunk_overlap"] = max(base_config["chunk_overlap"] * 0.8, 16)
        
        return base_config
```

#### 1.3 æ™ºèƒ½é…ç½®ç®¡ç†å™¨
```python
class SmartConfigManager:
    """æ™ºèƒ½é…ç½®ç®¡ç†å™¨"""
    def __init__(self):
        self.type_detector = DocumentTypeDetector()
        self.param_recommender = SmartParameterRecommender()
    
    def get_smart_config(self, text: str, user_preferences: Dict = None) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½é…ç½®"""
        # æ£€æµ‹æ–‡æ¡£ç±»å‹
        doc_type = self.type_detector.get_primary_type(text)
        
        # è·å–æ¨èå‚æ•°
        config = self.param_recommender.get_recommendation(doc_type, len(text))
        
        # åº”ç”¨ç”¨æˆ·åå¥½
        if user_preferences:
            config.update(user_preferences)
        
        # æ·»åŠ å…ƒæ•°æ®
        config["detected_type"] = doc_type
        config["confidence"] = self.type_detector.detect_document_type(text)[doc_type]
        
        return config
    
    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """éªŒè¯é…ç½®å‚æ•°"""
        errors = []
        
        if config.get("chunk_size", 0) <= 0:
            errors.append("chunk_size å¿…é¡»å¤§äº0")
        
        if config.get("chunk_overlap", 0) >= config.get("chunk_size", 1):
            errors.append("chunk_overlap å¿…é¡»å°äº chunk_size")
        
        if config.get("chunk_overlap", 0) < 0:
            errors.append("chunk_overlap ä¸èƒ½ä¸ºè´Ÿæ•°")
        
        return len(errors) == 0, errors
```

### 2. é«˜çº§æ–‡æœ¬åˆ†å‰²æŠ€æœ¯

#### 2.1 RecursiveCharacterTextSplitter
```python
class RecursiveCharacterTextSplitter:
    """é€’å½’å­—ç¬¦åˆ†å‰²å™¨"""
    def __init__(self, chunk_size=512, chunk_overlap=64, separators=None):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.separators = separators or ["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
    
    def split_text(self, text: str) -> List[str]:
        """é€’å½’åˆ†å‰²æ–‡æœ¬"""
        if not text.strip():
            return []
        
        # å°è¯•æŒ‰ä¸åŒåˆ†éš”ç¬¦åˆ†å‰²
        for separator in self.separators:
            if separator in text:
                splits = self._split_text_with_separator(text, separator)
                if len(splits) > 1:
                    return self._merge_splits(splits)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åˆ†éš”ç¬¦ï¼ŒæŒ‰å­—ç¬¦åˆ†å‰²
        return self._split_text_by_characters(text)
    
    def _split_text_with_separator(self, text: str, separator: str) -> List[str]:
        """ä½¿ç”¨æŒ‡å®šåˆ†éš”ç¬¦åˆ†å‰²æ–‡æœ¬"""
        if separator == "":
            return list(text)
        
        splits = text.split(separator)
        return [s + separator for s in splits[:-1]] + [splits[-1]]
    
    def _merge_splits(self, splits: List[str]) -> List[str]:
        """åˆå¹¶åˆ†å‰²ç»“æœï¼Œç¡®ä¿å—å¤§å°åˆé€‚"""
        merged_splits = []
        current_chunk = ""
        
        for split in splits:
            if len(current_chunk) + len(split) > self.chunk_size and current_chunk:
                merged_splits.append(current_chunk.strip())
                
                if self.chunk_overlap > 0:
                    overlap_start = max(0, len(current_chunk) - self.chunk_overlap)
                    current_chunk = current_chunk[overlap_start:] + split
                else:
                    current_chunk = split
            else:
                current_chunk += split
        
        if current_chunk.strip():
            merged_splits.append(current_chunk.strip())
        
        return merged_splits
    
    def _split_text_by_characters(self, text: str) -> List[str]:
        """æŒ‰å­—ç¬¦åˆ†å‰²æ–‡æœ¬"""
        chunks = []
        for i in range(0, len(text), self.chunk_size - self.chunk_overlap):
            chunk = text[i:i + self.chunk_size]
            if chunk.strip():
                chunks.append(chunk.strip())
        return chunks
```

#### 2.2 MarkdownHeaderTextSplitter
```python
class MarkdownHeaderTextSplitter:
    """Markdownæ ‡é¢˜åˆ†å‰²å™¨"""
    def __init__(self, headers_to_split_on=None):
        self.headers_to_split_on = headers_to_split_on or [
            ("#", "æ ‡é¢˜1"),
            ("##", "æ ‡é¢˜2"),
            ("###", "æ ‡é¢˜3"),
            ("####", "æ ‡é¢˜4"),
            ("#####", "æ ‡é¢˜5"),
            ("######", "æ ‡é¢˜6"),
        ]
        
        # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.header_patterns = []
        for header, name in self.headers_to_split_on:
            pattern = rf"^{re.escape(header)}\s+(.+)$"
            self.header_patterns.append((pattern, name, len(header)))
    
    def split_text(self, text: str) -> List[TextChunk]:
        """æŒ‰Markdownæ ‡é¢˜åˆ†å‰²æ–‡æœ¬"""
        lines = text.split('\n')
        chunks = []
        current_chunk = ""
        current_header = ""
        current_level = 0
        
        for line in lines:
            header_info = self._is_header_line(line)
            
            if header_info:
                if current_chunk.strip():
                    chunks.append(TextChunk(
                        content=current_chunk.strip(),
                        metadata={
                            "splitter": "markdown_header",
                            "header": current_header,
                            "level": current_level
                        }
                    ))
                
                current_header = header_info["title"]
                current_level = header_info["level"]
                current_chunk = line + "\n"
            else:
                current_chunk += line + "\n"
        
        if current_chunk.strip():
            chunks.append(TextChunk(
                content=current_chunk.strip(),
                metadata={
                    "splitter": "markdown_header",
                    "header": current_header,
                    "level": current_level
                }
            ))
        
        return chunks
    
    def _is_header_line(self, line: str) -> Optional[Dict[str, Any]]:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜è¡Œ"""
        for pattern, name, level in self.header_patterns:
            match = re.match(pattern, line.strip())
            if match:
                return {
                    "title": match.group(1).strip(),
                    "level": level,
                    "name": name
                }
        return None
```

#### 2.3 ParentChildTextSplitter
```python
class ParentChildTextSplitter:
    """çˆ¶å­å—åˆ†å‰²å™¨"""
    def __init__(self, parent_chunk_size=1024, child_chunk_size=256, child_overlap=32):
        self.parent_chunk_size = parent_chunk_size
        self.child_chunk_size = child_chunk_size
        self.child_overlap = child_overlap
        self.recursive_splitter = RecursiveCharacterTextSplitter(
            chunk_size=parent_chunk_size,
            chunk_overlap=64
        )
        self.child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=child_chunk_size,
            chunk_overlap=child_overlap
        )
    
    def split_text(self, text: str) -> List[TextChunk]:
        """ç”Ÿæˆçˆ¶å­å—ç»“æ„"""
        parent_chunks = self.recursive_splitter.split_text(text)
        
        all_chunks = []
        chunk_id_counter = 0
        
        for parent_chunk in parent_chunks:
            parent_id = f"parent_{chunk_id_counter}"
            chunk_id_counter += 1
            
            # æ·»åŠ çˆ¶å—
            parent_chunk_obj = TextChunk(
                content=parent_chunk,
                metadata={
                    "splitter": "parent_child",
                    "chunk_type": "parent",
                    "parent_id": None,
                    "chunk_id": parent_id
                }
            )
            all_chunks.append(parent_chunk_obj)
            
            # ç”Ÿæˆå­å—
            child_chunks = self.child_splitter.split_text(parent_chunk)
            
            for i, child_chunk in enumerate(child_chunks):
                child_id = f"child_{chunk_id_counter}_{i}"
                child_chunk_obj = TextChunk(
                    content=child_chunk,
                    metadata={
                        "splitter": "parent_child",
                        "chunk_type": "child",
                        "parent_id": parent_id,
                        "child_index": i,
                        "chunk_id": child_id
                    }
                )
                all_chunks.append(child_chunk_obj)
        
        return all_chunks
```

### 3. å¤šæ¨¡å‹Embeddingè·¯ç”±

#### 3.1 EmbeddingRouter
```python
class EmbeddingRouter:
    """å¤šæ¨¡å‹Embeddingè·¯ç”±"""
    def __init__(self):
        self.models = {
            "long_text": "bge-m3",
            "short_text": "text-embedding-ada-002",
            "code": "code-embedding-model",
            "technical": "bge-m3",
            "academic": "bge-m3",
            "news": "text-embedding-ada-002"
        }
    
    def get_embedding(self, text: str, text_type: str = "auto") -> List[float]:
        """æ ¹æ®æ–‡æœ¬ç±»å‹é€‰æ‹©æ¨¡å‹"""
        if text_type == "auto":
            text_type = self._detect_text_type(text)
        
        model_name = self.models.get(text_type, "bge-m3")
        return self._get_embedding_from_model(text, model_name)
    
    def _detect_text_type(self, text: str) -> str:
        """è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬ç±»å‹"""
        if len(text) > 1000:
            return "long_text"
        elif len(text) < 100:
            return "short_text"
        else:
            return "technical"
    
    def _get_embedding_from_model(self, text: str, model_name: str) -> List[float]:
        """ä»æŒ‡å®šæ¨¡å‹è·å–embedding"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„embeddingæœåŠ¡
        pass
```

#### 3.2 HybridEmbedding
```python
class HybridEmbedding:
    """çˆ¶å­è”åˆEmbedding"""
    def __init__(self, parent_weight=0.3, child_weight=0.7):
        self.parent_weight = parent_weight
        self.child_weight = child_weight
    
    def get_hybrid_embedding(self, parent_text: str, child_text: str) -> List[float]:
        """ç”Ÿæˆçˆ¶å­è”åˆå‘é‡"""
        parent_embedding = self._get_embedding(parent_text)
        child_embedding = self._get_embedding(child_text)
        
        # åŠ æƒå¹³å‡
        hybrid_embedding = []
        for p, c in zip(parent_embedding, child_embedding):
            hybrid_embedding.append(p * self.parent_weight + c * self.child_weight)
        
        return hybrid_embedding
    
    def _get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬embedding"""
        # è°ƒç”¨embeddingæœåŠ¡
        pass
```

### 4. æ··åˆæ£€ç´¢å¼•æ“

#### 4.1 HybridRetriever
```python
class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨"""
    def __init__(self, vector_weight=0.7, keyword_weight=0.3):
        self.vector_weight = vector_weight
        self.keyword_weight = keyword_weight
    
    async def retrieve(self, query: str, kb_ids: List[str], top_k: int = 10) -> List[Dict]:
        """æ··åˆæ£€ç´¢"""
        # å‘é‡æ£€ç´¢
        vector_results = await self._vector_search(query, kb_ids, top_k)
        
        # å…³é”®è¯æ£€ç´¢
        keyword_results = await self._keyword_search(query, kb_ids, top_k)
        
        # ç»“æœèåˆ
        return self._merge_results(vector_results, keyword_results)
    
    async def _vector_search(self, query: str, kb_ids: List[str], top_k: int) -> List[Dict]:
        """å‘é‡æ£€ç´¢"""
        pass
    
    async def _keyword_search(self, query: str, kb_ids: List[str], top_k: int) -> List[Dict]:
        """å…³é”®è¯æ£€ç´¢"""
        pass
    
    def _merge_results(self, vector_results: List[Dict], keyword_results: List[Dict]) -> List[Dict]:
        """èåˆæ£€ç´¢ç»“æœ"""
        pass
```

#### 4.2 MultiQueryExpander
```python
class MultiQueryExpander:
    """å¤šæŸ¥è¯¢æ‰©å±•å™¨"""
    def __init__(self, llm_client):
        self.llm_client = llm_client
    
    async def expand_query(self, query: str, num_expansions: int = 3) -> List[str]:
        """æ‰©å±•æŸ¥è¯¢"""
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆ{num_expansions}ä¸ªä¸åŒçš„è¡¨è¾¾æ–¹å¼ï¼Œä¿æŒè¯­ä¹‰ç›¸ä¼¼ä½†ç”¨è¯ä¸åŒï¼š
        
        åŸå§‹æŸ¥è¯¢ï¼š{query}
        
        è¯·ç”Ÿæˆï¼š
        """
        
        response = await self.llm_client.generate(prompt)
        expansions = self._parse_expansions(response)
        
        return [query] + expansions[:num_expansions-1]
    
    def _parse_expansions(self, response: str) -> List[str]:
        """è§£ææ‰©å±•ç»“æœ"""
        # è§£æLLMè¿”å›çš„æ‰©å±•æŸ¥è¯¢
        pass
```

#### 4.3 Reranker
```python
class Reranker:
    """é‡æ’åºå™¨"""
    def __init__(self, model_name="bge-reranker-v2-m3"):
        self.model_name = model_name
    
    async def rerank(self, query: str, documents: List[Dict]) -> List[Dict]:
        """é‡æ’åºæ–‡æ¡£"""
        # ä½¿ç”¨cross-encoderæ¨¡å‹é‡æ’åº
        pass
```

### 5. å…ƒæ•°æ®è¿‡æ»¤ç³»ç»Ÿ

#### 5.1 MetadataFilter
```python
class MetadataFilter:
    """å…ƒæ•°æ®è¿‡æ»¤å™¨"""
    def __init__(self):
        self.filters = {}
    
    def add_filter(self, field: str, value: Any, operator: str = "eq"):
        """æ·»åŠ è¿‡æ»¤æ¡ä»¶"""
        self.filters[field] = {"value": value, "operator": operator}
    
    def apply_filters(self, documents: List[Dict]) -> List[Dict]:
        """åº”ç”¨è¿‡æ»¤æ¡ä»¶"""
        filtered_docs = documents
        
        for field, filter_info in self.filters.items():
            value = filter_info["value"]
            operator = filter_info["operator"]
            
            if operator == "eq":
                filtered_docs = [doc for doc in filtered_docs if doc.get(field) == value]
            elif operator == "in":
                filtered_docs = [doc for doc in filtered_docs if doc.get(field) in value]
            elif operator == "gt":
                filtered_docs = [doc for doc in filtered_docs if doc.get(field, 0) > value]
            elif operator == "lt":
                filtered_docs = [doc for doc in filtered_docs if doc.get(field, 0) < value]
        
        return filtered_docs
```

## ğŸ”„ ä¼˜åŒ–Pipelineæµç¨‹

### æ™ºèƒ½å¤„ç†æµç¨‹
```
æ–‡æ¡£è¾“å…¥ 
    â†“
æ™ºèƒ½æ–‡æ¡£ç±»å‹æ£€æµ‹
    â†“
æ™ºèƒ½å‚æ•°æ¨è
    â†“
ç”¨æˆ·é…ç½®ç¡®è®¤/è°ƒæ•´
    â†“
Markdown Header åˆ†å— (å¦‚æœé€‚ç”¨)
    â†“
Recursive åˆ†å—
    â†“
Parent-Child ç»“æ„ç”Ÿæˆ (å¦‚æœå¯ç”¨)
    â†“
å¤šæ¨¡å‹Embeddingè·¯ç”±
    â†“
çˆ¶å­è”åˆå‘é‡åŒ– (å¦‚æœå¯ç”¨)
    â†“
å‘é‡åº“å…¥åº“ + Metadata
    â†“
æŸ¥è¯¢ Multi-query æ‰©å±•
    â†“
Hybrid Retrieval
    â†“
Metadata Filter
    â†“
Reranker é‡æ’åº
    â†“
Top-k ç»“æœè¿”å›
```

## ğŸ¨ ç”¨æˆ·ç•Œé¢è®¾è®¡

### 1. æ™ºèƒ½é…ç½®ç•Œé¢
```typescript
interface SmartConfigPanel {
  // æ–‡æ¡£ç±»å‹æ£€æµ‹ç»“æœ
  detectedType: string;
  confidence: number;
  
  // æ¨èé…ç½®
  recommendedConfig: {
    splitter: string;
    chunkSize: number;
    chunkOverlap: number;
    embeddingModel: string;
    useParentChild: boolean;
  };
  
  // ç”¨æˆ·è‡ªå®šä¹‰é…ç½®
  customConfig: {
    enabled: boolean;
    splitter: string;
    chunkSize: number;
    chunkOverlap: number;
    embeddingModel: string;
    useParentChild: boolean;
    parentChunkSize: number;
    childChunkSize: number;
  };
  
  // é«˜çº§é€‰é¡¹
  advancedOptions: {
    separators: string[];
    headerLevels: number[];
    semanticThreshold: number;
  };
}
```

### 2. é…ç½®é¢„è§ˆåŠŸèƒ½
- **å®æ—¶é¢„è§ˆ**: æ˜¾ç¤ºåˆ†å‰²ç»“æœé¢„è§ˆ
- **å‚æ•°è°ƒæ•´**: æ»‘å—å’Œè¾“å…¥æ¡†è°ƒæ•´å‚æ•°
- **æ•ˆæœå¯¹æ¯”**: ä¸åŒé…ç½®çš„æ•ˆæœå¯¹æ¯”
- **æ€§èƒ½é¢„ä¼°**: é¢„ä¼°å¤„ç†æ—¶é—´å’Œå­˜å‚¨éœ€æ±‚

### 3. æ‰¹é‡é…ç½®ç®¡ç†
- **é…ç½®æ¨¡æ¿**: ä¿å­˜å¸¸ç”¨é…ç½®ä¸ºæ¨¡æ¿
- **æ‰¹é‡åº”ç”¨**: å¯¹å¤šä¸ªæ–‡æ¡£åº”ç”¨ç›¸åŒé…ç½®
- **é…ç½®ç»§æ‰¿**: å­æ–‡æ¡£ç»§æ‰¿çˆ¶æ–‡æ¡£é…ç½®
- **é…ç½®ç‰ˆæœ¬**: é…ç½®å˜æ›´å†å²è®°å½•

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŒ‡æ ‡

### é¢„æœŸæå‡æ•ˆæœ
- **æ£€ç´¢ç²¾åº¦**ï¼šæå‡15-25%
- **å¬å›ç‡**ï¼šæå‡20-30%
- **å“åº”é€Ÿåº¦**ï¼šä¼˜åŒ–10-15%
- **ç”¨æˆ·ä½“éªŒ**ï¼šæ˜¾è‘—æ”¹å–„
- **é…ç½®æ•ˆç‡**ï¼šæå‡50-70%

### æŠ€æœ¯æŒ‡æ ‡
- **åˆ†å—é‡å ç‡**ï¼š20-30%
- **å‘é‡ç»´åº¦**ï¼š1536ç»´ï¼ˆå…¼å®¹OpenAIï¼‰
- **æ£€ç´¢æ•°é‡**ï¼šTop-10 -> Rerank -> Top-5
- **ç¼“å­˜ç­–ç•¥**ï¼šRedisç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢
- **é…ç½®å‡†ç¡®ç‡**ï¼š>85%

## ğŸ› ï¸ å®ç°è®¡åˆ’

### Phase 1: æ™ºèƒ½é…ç½®ç³»ç»Ÿ âœ…
- [x] DocumentTypeDetector
- [x] SmartParameterRecommender
- [x] SmartConfigManager
- [x] åŸºç¡€åˆ†å‰²å™¨å®ç°

### Phase 2: ç”¨æˆ·ç•Œé¢å¼€å‘
- [ ] æ™ºèƒ½é…ç½®é¢æ¿
- [ ] å‚æ•°è°ƒæ•´ç•Œé¢
- [ ] é¢„è§ˆåŠŸèƒ½
- [ ] é…ç½®æ¨¡æ¿ç®¡ç†

### Phase 3: Embeddingä¼˜åŒ–
- [ ] EmbeddingRouter
- [ ] HybridEmbedding
- [ ] å¤šæ¨¡å‹é›†æˆ

### Phase 4: æ£€ç´¢å¼•æ“
- [ ] HybridRetriever
- [ ] MultiQueryExpander
- [ ] Reranker

### Phase 5: ç³»ç»Ÿé›†æˆ
- [ ] Pipelineæ•´åˆ
- [ ] æ€§èƒ½æµ‹è¯•
- [ ] ç”¨æˆ·ç•Œé¢ä¼˜åŒ–

## ğŸ”§ æŠ€æœ¯æ ˆé€‰æ‹©

### æ ¸å¿ƒä¾èµ–
- **æ–‡æœ¬åˆ†å‰²**ï¼šè‡ªå®šä¹‰å®ç° + LangChainå‚è€ƒ
- **å‘é‡æ¨¡å‹**ï¼šbge-m3 + OpenAI + æœ¬åœ°æ¨¡å‹
- **é‡æ’åº**ï¼šbge-reranker-v2-m3
- **ç¼“å­˜**ï¼šRedis
- **æ•°æ®åº“**ï¼šPostgreSQL + Qdrant

### æ™ºèƒ½é…ç½®å‚æ•°
```yaml
smart_config:
  # æ–‡æ¡£ç±»å‹æ£€æµ‹
  type_detection:
    confidence_threshold: 0.6
    min_text_length: 100
    
  # å‚æ•°æ¨è
  recommendations:
    markdown:
      splitter: "markdown_header"
      chunk_size: 512
      chunk_overlap: 64
      embedding_model: "bge-m3"
      use_parent_child: true
    
    code:
      splitter: "recursive"
      chunk_size: 256
      chunk_overlap: 32
      embedding_model: "code-embedding-model"
      use_parent_child: false
    
    technical:
      splitter: "recursive"
      chunk_size: 384
      chunk_overlap: 48
      embedding_model: "bge-m3"
      use_parent_child: true
    
    academic:
      splitter: "semantic"
      chunk_size: 768
      chunk_overlap: 96
      embedding_model: "bge-m3"
      use_parent_child: true
    
    news:
      splitter: "recursive"
      chunk_size: 256
      chunk_overlap: 32
      embedding_model: "text-embedding-ada-002"
      use_parent_child: false
    
    manual:
      splitter: "markdown_header"
      chunk_size: 384
      chunk_overlap: 48
      embedding_model: "bge-m3"
      use_parent_child: true

  # é«˜çº§é…ç½®
  advanced:
    max_chunk_size: 1024
    min_chunk_size: 128
    max_overlap_ratio: 0.5
    semantic_threshold: 0.8
```

## ğŸ“ˆ ç›‘æ§ä¸è¯„ä¼°

### å…³é”®æŒ‡æ ‡
- **æ£€ç´¢å‡†ç¡®ç‡**ï¼šPrecision@K
- **å¬å›ç‡**ï¼šRecall@K
- **å“åº”æ—¶é—´**ï¼šå¹³å‡æŸ¥è¯¢å»¶è¿Ÿ
- **ç”¨æˆ·æ»¡æ„åº¦**ï¼šåé¦ˆè¯„åˆ†
- **é…ç½®å‡†ç¡®ç‡**ï¼šæ™ºèƒ½é…ç½®çš„å‡†ç¡®æ€§

### è¯„ä¼°æ–¹æ³•
- **ç¦»çº¿è¯„ä¼°**ï¼šæ ‡å‡†æ•°æ®é›†æµ‹è¯•
- **åœ¨çº¿è¯„ä¼°**ï¼šA/Bæµ‹è¯•
- **ç”¨æˆ·åé¦ˆ**ï¼šæ»¡æ„åº¦è°ƒæŸ¥
- **é…ç½®éªŒè¯**ï¼šé…ç½®æ¨èå‡†ç¡®æ€§æµ‹è¯•

## ğŸš€ éƒ¨ç½²ç­–ç•¥

### æ¸è¿›å¼éƒ¨ç½²
1. **ç°åº¦å‘å¸ƒ**ï¼š10%æµé‡æµ‹è¯•
2. **æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶æŒ‡æ ‡è·Ÿè¸ª
3. **å…¨é‡å‘å¸ƒ**ï¼šé€æ­¥æ‰©å¤§èŒƒå›´
4. **æ•ˆæœè¯„ä¼°**ï¼šæŒç»­ä¼˜åŒ–

### å›æ»šæœºåˆ¶
- **å¿«é€Ÿå›æ»š**ï¼š5åˆ†é’Ÿå†…å›æ»šåˆ°ç¨³å®šç‰ˆæœ¬
- **æ•°æ®å¤‡ä»½**ï¼šå®šæœŸå¤‡ä»½å‘é‡åº“
- **ç›‘æ§å‘Šè­¦**ï¼šå¼‚å¸¸æƒ…å†µåŠæ—¶é€šçŸ¥

---

*æœ¬æ–‡æ¡£å°†éšç€å®ç°è¿›åº¦æŒç»­æ›´æ–°* 